{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMZL0Fzh+axJJ/7UZEzEmwb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viti990/my_own_llama/blob/main/llamav27b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aviator LLaMA\n",
        "\n",
        "This notebook aims at reconstructing LLAMA 2 7B architecture and use the model weights trained from meta to learn how it is done!\n",
        "\n",
        "Also the aim is to adapt the model with LoRA and QLoRA for PEFT!\n",
        "\n",
        "The fine tuning will be done with aviation regulations from 14 CFR...\n"
      ],
      "metadata": {
        "id": "H57i8tK00XR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.0 Downloading the weights\n",
        "\n",
        "Downloading the weights from meta for 7B-chat (i want the model to be able to respond to questions from the requirements)\n",
        "for this one must go to the meta website and request access, then go the github and use the download.sh scrip as shown below.\n"
      ],
      "metadata": {
        "id": "j5YxiWmS30_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/meta-llama/llama/\n",
        "!mv ./llama/download.sh ./\n",
        "!rm -rf llama\n",
        "!bash download.sh\n",
        "!rm -rf LICENSE USE_POLICY.md tokenizer_checklist.chk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTgN2c7aYSDA",
        "outputId": "1c66691e-07a2-45cd-a04e-54a202bd1aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama'...\n",
            "remote: Enumerating objects: 464, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 464 (delta 17), reused 33 (delta 12), pack-reused 417\u001b[K\n",
            "Receiving objects: 100% (464/464), 1.12 MiB | 24.30 MiB/s, done.\n",
            "Resolving deltas: 100% (235/235), done.\n",
            "Enter the URL from email: https://download.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidGQxOHdlcHp2M21ubGl6YzJqZTQ0Nm40IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDE5ODM0OX19fV19&Signature=qbEw3yZ-aOH%7ElMJPCaqdLdxv6cFeKlza-RFTWxnd54SEePs6awC85oYIB1Qr9pk6dSp6kpBcBJRwtzJSEN0dj-WPmvUqVyZU4M3q2A-qakJUhO3hoo8lhroBxTYHOVCc0n8IQTMNLSkYsBzpu7Sfdeizkq%7EkBzCB140NNChA4QcjWgaF1P-KWPqOLAtgC1b1VPHo25qB1sbZTrOix3wmVatrHg79RjsjHbqIpL%7ECmZhBtpkauJG4JG2FMZNiPCH3NzG8am2rociEogyIFoeZTKBTKeE7NdOOHCNcFe6tanQMo7FmRXMWwnmeRW5ShwpU6fmfp1qaJH4iFYcQrVf-Kw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1616987309079799\n",
            "\n",
            "Enter the list of models to download without spaces (7B,13B,70B,7B-chat,13B-chat,70B-chat), or press Enter for all: 7B-chat\n",
            "Downloading LICENSE and Acceptable Usage Policy\n",
            "--2024-07-04 17:45:07--  https://download.llamameta.net/LICENSE?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidGQxOHdlcHp2M21ubGl6YzJqZTQ0Nm40IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDE5ODM0OX19fV19&Signature=qbEw3yZ-aOH%7ElMJPCaqdLdxv6cFeKlza-RFTWxnd54SEePs6awC85oYIB1Qr9pk6dSp6kpBcBJRwtzJSEN0dj-WPmvUqVyZU4M3q2A-qakJUhO3hoo8lhroBxTYHOVCc0n8IQTMNLSkYsBzpu7Sfdeizkq%7EkBzCB140NNChA4QcjWgaF1P-KWPqOLAtgC1b1VPHo25qB1sbZTrOix3wmVatrHg79RjsjHbqIpL%7ECmZhBtpkauJG4JG2FMZNiPCH3NzG8am2rociEogyIFoeZTKBTKeE7NdOOHCNcFe6tanQMo7FmRXMWwnmeRW5ShwpU6fmfp1qaJH4iFYcQrVf-Kw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1616987309079799\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.56, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7020 (6.9K) [binary/octet-stream]\n",
            "Saving to: ‘./LICENSE’\n",
            "\n",
            "./LICENSE           100%[===================>]   6.86K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-04 17:45:07 (1.37 GB/s) - ‘./LICENSE’ saved [7020/7020]\n",
            "\n",
            "--2024-07-04 17:45:07--  https://download.llamameta.net/USE_POLICY.md?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidGQxOHdlcHp2M21ubGl6YzJqZTQ0Nm40IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDE5ODM0OX19fV19&Signature=qbEw3yZ-aOH%7ElMJPCaqdLdxv6cFeKlza-RFTWxnd54SEePs6awC85oYIB1Qr9pk6dSp6kpBcBJRwtzJSEN0dj-WPmvUqVyZU4M3q2A-qakJUhO3hoo8lhroBxTYHOVCc0n8IQTMNLSkYsBzpu7Sfdeizkq%7EkBzCB140NNChA4QcjWgaF1P-KWPqOLAtgC1b1VPHo25qB1sbZTrOix3wmVatrHg79RjsjHbqIpL%7ECmZhBtpkauJG4JG2FMZNiPCH3NzG8am2rociEogyIFoeZTKBTKeE7NdOOHCNcFe6tanQMo7FmRXMWwnmeRW5ShwpU6fmfp1qaJH4iFYcQrVf-Kw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1616987309079799\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.56, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4766 (4.7K) [binary/octet-stream]\n",
            "Saving to: ‘./USE_POLICY.md’\n",
            "\n",
            "./USE_POLICY.md     100%[===================>]   4.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-04 17:45:07 (1.11 GB/s) - ‘./USE_POLICY.md’ saved [4766/4766]\n",
            "\n",
            "Downloading tokenizer\n",
            "--2024-07-04 17:45:07--  https://download.llamameta.net/tokenizer.model?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidGQxOHdlcHp2M21ubGl6YzJqZTQ0Nm40IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDE5ODM0OX19fV19&Signature=qbEw3yZ-aOH%7ElMJPCaqdLdxv6cFeKlza-RFTWxnd54SEePs6awC85oYIB1Qr9pk6dSp6kpBcBJRwtzJSEN0dj-WPmvUqVyZU4M3q2A-qakJUhO3hoo8lhroBxTYHOVCc0n8IQTMNLSkYsBzpu7Sfdeizkq%7EkBzCB140NNChA4QcjWgaF1P-KWPqOLAtgC1b1VPHo25qB1sbZTrOix3wmVatrHg79RjsjHbqIpL%7ECmZhBtpkauJG4JG2FMZNiPCH3NzG8am2rociEogyIFoeZTKBTKeE7NdOOHCNcFe6tanQMo7FmRXMWwnmeRW5ShwpU6fmfp1qaJH4iFYcQrVf-Kw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1616987309079799\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.56, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2024-07-04 17:45:07--  https://download.llamameta.net/tokenizer_checklist.chk?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidGQxOHdlcHp2M21ubGl6YzJqZTQ0Nm40IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDE5ODM0OX19fV19&Signature=qbEw3yZ-aOH%7ElMJPCaqdLdxv6cFeKlza-RFTWxnd54SEePs6awC85oYIB1Qr9pk6dSp6kpBcBJRwtzJSEN0dj-WPmvUqVyZU4M3q2A-qakJUhO3hoo8lhroBxTYHOVCc0n8IQTMNLSkYsBzpu7Sfdeizkq%7EkBzCB140NNChA4QcjWgaF1P-KWPqOLAtgC1b1VPHo25qB1sbZTrOix3wmVatrHg79RjsjHbqIpL%7ECmZhBtpkauJG4JG2FMZNiPCH3NzG8am2rociEogyIFoeZTKBTKeE7NdOOHCNcFe6tanQMo7FmRXMWwnmeRW5ShwpU6fmfp1qaJH4iFYcQrVf-Kw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1616987309079799\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.56, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50 [binary/octet-stream]\n",
            "Saving to: ‘./tokenizer_checklist.chk’\n",
            "\n",
            "./tokenizer_checkli 100%[===================>]      50  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-04 17:45:07 (64.4 MB/s) - ‘./tokenizer_checklist.chk’ saved [50/50]\n",
            "\n",
            "tokenizer.model: OK\n",
            "Downloading llama-2-7b-chat\n",
            "--2024-07-04 17:45:07--  https://download.llamameta.net/llama-2-7b-chat/consolidated.00.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidGQxOHdlcHp2M21ubGl6YzJqZTQ0Nm40IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDE5ODM0OX19fV19&Signature=qbEw3yZ-aOH%7ElMJPCaqdLdxv6cFeKlza-RFTWxnd54SEePs6awC85oYIB1Qr9pk6dSp6kpBcBJRwtzJSEN0dj-WPmvUqVyZU4M3q2A-qakJUhO3hoo8lhroBxTYHOVCc0n8IQTMNLSkYsBzpu7Sfdeizkq%7EkBzCB140NNChA4QcjWgaF1P-KWPqOLAtgC1b1VPHo25qB1sbZTrOix3wmVatrHg79RjsjHbqIpL%7ECmZhBtpkauJG4JG2FMZNiPCH3NzG8am2rociEogyIFoeZTKBTKeE7NdOOHCNcFe6tanQMo7FmRXMWwnmeRW5ShwpU6fmfp1qaJH4iFYcQrVf-Kw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1616987309079799\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.56, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2024-07-04 17:45:07--  https://download.llamameta.net/llama-2-7b-chat/params.json?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidGQxOHdlcHp2M21ubGl6YzJqZTQ0Nm40IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDE5ODM0OX19fV19&Signature=qbEw3yZ-aOH%7ElMJPCaqdLdxv6cFeKlza-RFTWxnd54SEePs6awC85oYIB1Qr9pk6dSp6kpBcBJRwtzJSEN0dj-WPmvUqVyZU4M3q2A-qakJUhO3hoo8lhroBxTYHOVCc0n8IQTMNLSkYsBzpu7Sfdeizkq%7EkBzCB140NNChA4QcjWgaF1P-KWPqOLAtgC1b1VPHo25qB1sbZTrOix3wmVatrHg79RjsjHbqIpL%7ECmZhBtpkauJG4JG2FMZNiPCH3NzG8am2rociEogyIFoeZTKBTKeE7NdOOHCNcFe6tanQMo7FmRXMWwnmeRW5ShwpU6fmfp1qaJH4iFYcQrVf-Kw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1616987309079799\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.56, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2024-07-04 17:45:07--  https://download.llamameta.net/llama-2-7b-chat/checklist.chk?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidGQxOHdlcHp2M21ubGl6YzJqZTQ0Nm40IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDE5ODM0OX19fV19&Signature=qbEw3yZ-aOH%7ElMJPCaqdLdxv6cFeKlza-RFTWxnd54SEePs6awC85oYIB1Qr9pk6dSp6kpBcBJRwtzJSEN0dj-WPmvUqVyZU4M3q2A-qakJUhO3hoo8lhroBxTYHOVCc0n8IQTMNLSkYsBzpu7Sfdeizkq%7EkBzCB140NNChA4QcjWgaF1P-KWPqOLAtgC1b1VPHo25qB1sbZTrOix3wmVatrHg79RjsjHbqIpL%7ECmZhBtpkauJG4JG2FMZNiPCH3NzG8am2rociEogyIFoeZTKBTKeE7NdOOHCNcFe6tanQMo7FmRXMWwnmeRW5ShwpU6fmfp1qaJH4iFYcQrVf-Kw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1616987309079799\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.56, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "Checking checksums\n",
            "consolidated.00.pth: OK\n",
            "params.json: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Creating the architecture"
      ],
      "metadata": {
        "id": "REMnXCWz4WaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Importing everything..."
      ],
      "metadata": {
        "id": "ClefDRdS42cY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw7Pu7e8NUks"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ModelArgs:\n",
        "  dim: int=4096\n",
        "  n_layers: int=32\n",
        "  n_heads: int=32 #number of heads for the queries\n",
        "  n_kv_heads: Optional[int]=None #number of values for the key and value\n",
        "  vocab_size: int = -1 # This will be set when we load the tokenizer\n",
        "  multiple_of: int = 256\n",
        "  ffn_dim_multiplier: Optional[float]=None\n",
        "  norm_eps: float = 1e-5\n",
        "\n",
        "  #Needed for KV cache\n",
        "  max_batch_size: int=32\n",
        "  max_seq_len: int=2048\n",
        "\n",
        "  device: str=None\n",
        "\n",
        "def precompute_theta_pos_frequencies(head_dim: int, seq_len: int, device: str, theta: float = 10000.0 ):\n",
        "  # as written in the paper, the dimension of the embedding must be even.\n",
        "  assert head_dim % 2 ==0, \"Dimension must be divisible by 2\"\n",
        "  # Build the theta parameters\n",
        "  # According to the formula theta_i = 10000^ (-2(i-1)/dim) for i = [1, 2, ... dim / 2]\n",
        "  # Shape: (head_dim / 2)\n",
        "  theta_numerator = torch.arange(0, head_dim, 2).float()\n",
        "  theta = 1.0 / (theta ** (theta_numerator/head_dim)).to(device)\n",
        "  # Construct the positions (the \"m\" parameter)\n",
        "  # shape: (seq_len)\n",
        "  m = torch.arange(seq_len, device=device)\n",
        "  # Multiply each theta by each position using the outer product\n",
        "  # Shape: {Seq_Len} outer_product * (head_dim / 2) -> (seq_len, head_dim / 2)\n",
        "  freqs = torch.outer(m, theta).float()\n",
        "  # we can compute complex numbers in the polar form c = R * exp(i * m * theta), where r = 1 as follows:\n",
        "  freqs_complex = torch.polar(torch.ones_like(freqs), freqs)\n",
        "\n",
        "  return freqs_complex\n",
        "\n",
        "def apply_rotary_embedding(x: torch.Tensor, freqs_complex: torch.Tensor, device: str):\n",
        "  # (B, Seq_len, H, Head_dim) -> (B,Seq_len, H, head_dim/2)\n",
        "  x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:1], -1, 2))\n",
        "  # (Seq_len, head_dim / 2) -> (1, Seq_len, head_dim / 2)\n",
        "  freqs_complex = freqs_complex.unsqueeze(0).unsqueeze(2)\n",
        "  # (B, Seq_len, H, head_dim / 2) * (1, Seq_len, 1, head_dim / 2) * (B, seq_len, H, Head_Dim / 2)\n",
        "  x_rotated = x_complex * freqs_complex\n",
        "  # (B, seq_len, H, head_dim / 2) -> (B, seq_len, H, head_dim / 2, 2)\n",
        "  x_out = torch.view_as_real(x_rotated)\n",
        "  #(B, seq_len, H, head_dim / 2, 2) -> (B, seq_len, H, head_dim)\n",
        "  x_out = x_out.reshape(*x.shape)\n",
        "\n",
        "  return x_out.type_as(x).to(device)\n",
        "\n",
        "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
        "  batch_size, seq_len, n_kv_heads = x.shape\n",
        "  if n_rep == 1:\n",
        "     return x\n",
        "  else:\n",
        "    return (\n",
        "        x[:, :, :, None, :]\n",
        "        .expand(batch_size,seq_len, n_kv_heads, n_rep, head_dim)\n",
        "        .reshape(batch_size, seq_len, n_kv_heads * n_rep, head_dim)\n",
        "    )\n",
        "\n",
        "class RMSNorm(nn.Module):\n",
        "  def __init__(self, dim: int, eps: float=1e-5) -> None:\n",
        "    super().__init__()\n",
        "    self.eps = eps\n",
        "    # the gamma parameter\n",
        "    self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "  def _norm(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    # (B, seq_len, dim)\n",
        "    # rsqrt: 1/sqrt(x)\n",
        "    return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True)) + self.eps\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    #(dim) * (B, Seq_len, dim) * (B, seq_len, dim)\n",
        "    return self.weight * self._norm(x.float()).type_as(x)\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self, args: ModelArgs):\n",
        "    super().__init__()\n",
        "    # Indicates the number of heads fot the key and values\n",
        "    self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads\n",
        "    # Indicates the number of heads for the queries\n",
        "    self.n_heads_q = args.n_heads\n",
        "    # Indicates how many times the heads of keys and values should be repeated to match the head of the queries\n",
        "    self.n_rep = self.n_heads_q // self.n_kv_heads\n",
        "    # Indicates the dimension of each head\n",
        "    self.head_dim = args.dim // args.n_heads\n",
        "\n",
        "    self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias = False)\n",
        "    self.wk = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias = False)\n",
        "    self.wv = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias = False)\n",
        "    self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim,  bias = False)\n",
        "\n",
        "    self.cache_k = torch.zeros((args.max_batch_size, args.max_seq_len, self.n_kv_heads, self.head_dim))\n",
        "    self.cache_v = torch.zeros((args.max_batch_size, args.max_seq_len, self.n_kv_heads, self.head_dim))\n",
        "\n",
        "  def forward(self, x: torch.Tensor, start_pos: int, freqs_complex: torch.Tensor):\n",
        "    batch_size, seq_len, _ = x.shape #(B, 1, dim)\n",
        "\n",
        "    # Apply the wq, wk, wv matrices to queries, keys and values\n",
        "    # (B, 1, dim) -> (B, 1, H_Q * head_dim)\n",
        "    xq = self.wq(x)\n",
        "\n",
        "    # (B, 1, dim) -> (B, 1, H_KV * head_dim)\n",
        "    xk = self.wk(x)\n",
        "    xv = self.wv(x)\n",
        "\n",
        "    # (B, 1, H_Q * head_dim) -> (B, 1, H_Q, head_dim)\n",
        "    xq = xq.view(batch_size, 1, self.n_heads_q, self.head_dim)\n",
        "\n",
        "    # (B, 1, H_KV * head_dim) -> (B, 1, H_KV, head_dim)\n",
        "    xk = xk.view(batch_size, 1, self.n_kv_heads, self.head_dim)\n",
        "    xv = xv.view(batch_size, 1, self.n_kv_heads, self.head_dim)\n",
        "\n",
        "    # Does not change the shape of the tensors\n",
        "    xq = apply_rotary_embedding(xq, freqs_complex, device = x.device)\n",
        "    xk = apply_rotary_embedding(xk, freqs_complex, device = x.device)\n",
        "\n",
        "    # Replace the entry in the cache fot this token\n",
        "    self.cache_k[:batch_size, start_pos:start_pos+seq_len] = xk\n",
        "    self.cache_v[:batch_size, start_pos:start_pos+seq_len] = xv\n",
        "\n",
        "    # Retrieve all the cached keys and values so far\n",
        "    # (B, seq_len_KV, H_KV, head_dim)\n",
        "    keys = self.cache_k[:batch_size, 0:start_pos+seq_len]\n",
        "    values = self.cache_v[:batch_size, 0:start_pos+seq_len]\n",
        "\n",
        "    # Repeat the heads of the K and V to reach the number of heads of the queries\n",
        "    keys = repeat_kv(keys, self.n_rep)\n",
        "    values = repeat_kv(values, self.n_rep)\n",
        "\n",
        "    # (B, 1, H_Q, head_dim) -> (B, H_Q, 1, head_dim)\n",
        "    xq = xq.transpose(1, 2)\n",
        "    keys = keys.transpose(1, 2)\n",
        "    values = values.transpose(1, 2)\n",
        "\n",
        "    # (B, H_Q, 1, seq_len) @ (B, H_Q, seq_len_kv, head_dim) -> (B, H_Q, 1, head_dim)\n",
        "    scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
        "    scores = F.softmax(scores, dim=-1).type_as(xq)\n",
        "\n",
        "    # (B, H_Q, 1, head_dim) -> (B, 1, H_Q, head_dim) -> (B, 1, dim)\n",
        "    output = torch.matmul(scores, values)\n",
        "    output = output.transpose(1, 2).contiguous().view(batch_size, seq_len, -1)\n",
        "\n",
        "    return self.wo(output)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, args: ModelArgs):\n",
        "    super().__init__()\n",
        "\n",
        "    hidden_dim = 4 * args.dim\n",
        "    hidden_dim = int(2 * hidden_dim / 3)\n",
        "    if args.ffn_dim_multiplier is not None:\n",
        "      hidden_dim = int(args.ffn_dim_multiplier * hidden_dim)\n",
        "    # round the hidden_dim to the nearest multiple of the multiple_of parameter\n",
        "    hidden_dim = args.multiple_of * ((hidden_dim + args.multiple_of - 1) // args.multiple_of)\n",
        "\n",
        "    self.w1 = nn.Linear(args.dim, hidden_dim, bias=False)\n",
        "    self.w2 = nn.Linear(hidden_dim, args.dim, bias=False)\n",
        "    self.w3 = nn.Linear(args.dim, hidden_dim, bias=False)\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    swish = F.silu(self.w1(x))\n",
        "    x_V = self.w3(x)\n",
        "    x = swish * x_V\n",
        "    x= self.w2(x)\n",
        "    return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, args: ModelArgs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.n_head=args.n_heads\n",
        "    self.dim = args.dim\n",
        "    self.head_dim = args.dim // args.n_heads\n",
        "\n",
        "    self.attention = SelfAttention(args)\n",
        "    self.feed_forward = FeedForward(args)\n",
        "\n",
        "    # Normalization BEFORE the self attention\n",
        "    self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
        "    # Normalization BEFORE the feed forward block\n",
        "    self.ffn_norm = RMSNorm(args.dim, eps= args.norm_eps)\n",
        "\n",
        "  def forward(self, x: torch.Tensor, start_pos: int, freqs_complex: torch.Tensor):\n",
        "    # (B, seq_len, Dim) + (B, seq_len, Dim) -> (B, seq_len, Dim)\n",
        "    h = x + self.attention.forward(self.attention_norm(x), start_pos,freqs_complex)\n",
        "    out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "\n",
        "  def __init__(self, args: ModelArgs) -> None:\n",
        "    super().__init__()\n",
        "    assert args.vocab_size != -1, \"Vocab size must be set\"\n",
        "\n",
        "    self.args = args\n",
        "    self.vocab_size = args.vocab_size\n",
        "    self.n_layers = args.n_layers\n",
        "    self.tok_embeddings = nn.Embedding(self.vocab_size, args.dim)\n",
        "\n",
        "    self.layers = nn.ModuleList()\n",
        "    for _ in range(args.n_layers):\n",
        "      self.layers.append(EncoderBlock(args))\n",
        "\n",
        "    self.norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
        "    self.output = nn.Linear(args.dim, self.vocab_size, bias=False)\n",
        "\n",
        "    self.freqs_complex = precompute_theta_pos_frequencies(self.args.dim // self.args.n_heads, self.args.max_seq_len * 2, device=self.args.device)\n",
        "\n",
        "  def forward(self, tokens: torch.Tensor, start_pos: int):\n",
        "    # (B, seq_len)\n",
        "    batch_size, seq_len = tokens.shape\n",
        "    assert seq_len == 1, \"only one token at a time can be processed\" #this only works for inference for training you must process more than 1 token at a time and must also remove KV cache\n",
        "\n",
        "    # (B, Seq_Len) -> (B, seq_len, Dim)\n",
        "    h = self.tok_embeddings(tokens)\n",
        "\n",
        "    # Retrieve the pairs (m, theta) corresponding to the positions [start_pos, start_pos + seq_len]\n",
        "    freqs_complex = self.freqs_complex[start_pos:start_pos+seq_len]\n",
        "\n",
        "    # Consecutively apply all the encoder layers\n",
        "    for layer in self.layers:\n",
        "      h = layer(h, start_pos, freqs_complex)\n",
        "    h = self.norm(h)\n",
        "\n",
        "    output = self.output(h).float()\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "__qz9L6dqfKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "import torch\n",
        "import time\n",
        "from pathlib import Path\n",
        "import json\n",
        "from sentencepiece import SentencePieceProcessor\n",
        "from tqdm import tqdm\n",
        "\n",
        "#from model import ModelArgs, Transformer\n",
        "\n",
        "class LLaMA:\n",
        "\n",
        "  def __init__(self, model: Transformer, tokenizer: SentencePieceProcessor, model_args: ModelArgs):\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.args = model_args\n",
        "\n",
        "  @staticmethod\n",
        "  def build(checkpoints_dir: str, tokenizer_path: str, load_model: bool, max_seq_len: int, max_batch_size: int, device: str):\n",
        "    prev_time = time.time()\n",
        "    if load_model:\n",
        "      checkpoints = sorted(Path(checkpoints_dir).glob('*.pth'))\n",
        "      assert len(checkpoints) > 0, \"No checkpoints files found\"\n",
        "      chk_path = checkpoints[0]\n",
        "      print(f\"Loading checkpoint {chk_path}\")\n",
        "      checkpoint = torch.load(chk_path, map_location=\"cpu\")\n",
        "      print(f\"Loaded checkpoint in {(time.time() - prev_time):.2f}s\")\n",
        "      prev_time = time.time()\n",
        "\n",
        "    with open (Path(checkpoints_dir) / \"params.json\", \"r\") as f:\n",
        "      params = json.loads(f.read())\n",
        "\n",
        "    model_args: ModelArgs = ModelArgs(\n",
        "      max_seq_len=max_seq_len,\n",
        "      max_batch_size=max_batch_size,\n",
        "      device=device,\n",
        "      **params\n",
        "    )\n",
        "\n",
        "    tokenizer = SentencePieceProcessor()\n",
        "    tokenizer.load(tokenizer_path)\n",
        "    model_args.vocab_size = tokenizer.vocab_size()\n",
        "\n",
        "    if device == \"cuda\":\n",
        "      torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
        "    else:\n",
        "      torch.set_default_tensor_type(torch.BFloat16Tensor)\n",
        "\n",
        "    model = Transformer(model_args).to(device)\n",
        "    if load_model:\n",
        "      del checkpoint[\"rope.freqs\"]\n",
        "      model.load_state_dict(checkpoint, strict=True)\n",
        "      print(f\"loaded state dict in {(time.time() - prev_time):.2f}s\")\n",
        "\n",
        "    return LLaMA(model, tokenizer, model_args)\n",
        "\n",
        "    def text_completion(self, prompts: list[str], temperature: float = 0.6, top_p: float = 0.9, max_gen_len: Optional[int] = None):\n",
        "      if max_gen_len is None:\n",
        "        max_gen_len = self.args.max_seq_len - 1\n",
        "      # Convert each prompt into tokens\n",
        "      prompt_tokens = [self.tokenizer.encode(prompt, out_type=int, add_bos=True, add_eos=False) for prompt in prompts]\n",
        "      # Make sure the batch size is not too large\n",
        "      batch_size = len(prompt_tokens)\n",
        "      assert bath-size <= self.args.max_batch_size\n",
        "      max_prompt_len = max(len(prompt) for prompt in prompt_tokens)\n",
        "      # make sure the prompt length is not larger than the maximum seq length\n",
        "      assert max_prompt_len <= self.args.max_seq_len\n",
        "      total_len = min(self.args.max_seq_len, max_gen_len + max_prompt_len)\n",
        "\n",
        "      # Create  the list that will contain the generated tokens, along with the initial prompt tokens\n",
        "      pad_id = self.tokenizer.pad_id()\n",
        "      tokens = torch.full((batch_size, total_len), pad_id, dtype = torch.long, device=device)\n",
        "      for k, t in enumerate(prompt_tokens):\n",
        "        # Populate the initial tokens with the prompt token, False otherwise\n",
        "        tokens[k, :len(t)] = torch.tensor(t, dtype=torch.long, device=device)\n",
        "\n",
        "      eos_reached = torch.Tensor([False] * batch_size, device=device)"
      ],
      "metadata": {
        "id": "HgBUJKJphoBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "allow_cuda = False\n",
        "device = \"cuda\" if torch.cuda.is_available() and allow_cuda else \"cpu\"\n",
        "\n",
        "model = LLaMA.build(\n",
        "    checkpoints_dir=\"llama-2-7b-chat\",\n",
        "    tokenizer_path=\"./tokenizer.model\",\n",
        "    load_model=True,\n",
        "    max_seq_len=1024,\n",
        "    max_batch_size=3,\n",
        "    device=device\n",
        ")\n",
        "print(\"All ok\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhjvltaanBkD",
        "outputId": "c054af14-c010-46a0-8183-d37824c0a65f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint llama-2-7b-chat/consolidated.00.pth\n",
            "Loaded checkpoint in 5.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:747: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:431.)\n",
            "  _C._set_default_tensor_type(t)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded state dict in 46.14s\n",
            "All ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XMotm-8e112v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}